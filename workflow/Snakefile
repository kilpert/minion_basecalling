import glob
import json
import os
import pandas as pd
import re
from tabulate import tabulate
import itertools


## Resources ###########################################################################################################
try:
    workflow.global_resources["gpu_requests"] = config["gpu_requests"]
except:
    workflow.global_resources["gpu_requests"] = 1


## 1st level of config variable definition: config.yaml ################################################################
try:
    configfile: "config/config.yaml"
except:
    pass


## 2nd level of config variable definition: snakemake command line args (overwrites previous definitions) ##############


## 3rd level of config variable definition: Snakefile (overwrites previous definitions) ################################

## outdir
try:
    results = config["outdir"]
except:
    config["outdir"] = "results"
    results = config["outdir"]


try:
    config["guppy_basecaller"]
except:
    config["guppy_basecaller"] = "guppy_basecaller"


try:
    config["guppy_cfg"] = [re.search("(.+).cfg", cfg).group(1) for cfg in config["guppy_cfg"]]
except:
    config["guppy_cfg"] = "flowcell+kit"
cfg_type = config["guppy_cfg"]


try:
    config["run"]["experiment_id"]
except:
    config["run"]["experiment_id"] = os.path.basename(config["run"]["input_dir"])
run = config["run"]["experiment_id"]


try:
    guppy = list(config["guppy_basecaller"].keys())
except:
    guppy = "guppy"


try:
    config["pycoqc"]
except:
    config["pycoqc"] = ""


try:
    config["nanoplot"]
except:
    config["nanoplot"] = ""


try:
    wait_log = config["wait_log"]
except:
    wait_log = os.path.join(results, "wait.log")


try:
    config["dorado_basecaller"]
except:
    config["dorado_basecaller"] = "dorado_basecaller"


# try:
#     dorado = list(config["dorado_basecaller"].keys())
# except:
#     dorado = "dorado"


for dorado in config["dorado_basecaller"].keys():
    try:
        config["dorado_basecaller"][dorado]["mode"]
    except:
        config["dorado_basecaller"][dorado]["mode"] = ["fast"]


for dorado in config["dorado_basecaller"].keys():
    try:
        config["dorado_basecaller"][dorado]["extra"]
    except:
        config["dorado_basecaller"][dorado]["extra"] = "--no-trim"


## config ##############################################################################################################

print("{:#^60}".format(" Config "))
print(json.dumps(config, sort_keys=True, indent=4))


## sample_sheet ########################################################################################################

print("{:#^60}".format(" Sample Sheet "))

try:
    df = pd.read_csv(config["run"]["sample_sheet"])
    print(tabulate(df, headers='keys'))
    samples = sorted(df.alias.tolist())
except:
    print("Warning! Unable to read sample sheet:", config["run"]["sample_sheet"])
    exit(1)


def get_dfl(df, barcodes):
    """extend df by barcodes"""
    dfb = pd.DataFrame({"barcode": barcodes, "alias": barcodes })
    return pd.concat([df, dfb.loc[~dfb["barcode"].isin(df["barcode"].values)]])


def get_alias(df, barcode):
    return df[df["barcode"]==barcode]["alias"].values[0]


def get_barcode(df, alias):
        return df[df["alias"]==alias]["barcode"].values[0]


## include #############################################################################################################

include: "rules/dorado.smk"
include: "rules/qc.smk"


## variables ###########################################################################################################
print("{:#^60}".format(" Variables "))
print(f"results: {results}")
print(f"guppy: {guppy}")
print(f"cfg_type: {cfg_type}")
print(f"run: {run}")
samples.append("unclassified")
print(f"samples:", samples, len(samples))



## snakemake: all ######################################################################################################

print("{:#^60}".format(" Workflow "))


## rule all ############################################################################################################

def run_dorado():
    file_list = []

    for dorado in config["dorado_basecaller"].keys():

        file_list.append(
            expand("{results}/{run}/{dorado}/{model}/dorado/{run}.{model}.dorado.{ext}",
                results=results,
                dorado=dorado,
                model=config["dorado_basecaller"][dorado]["model"],
                run=run,
                ext=["bam", "summary.tsv.gz"]
            )
        )

        file_list.append(
            expand("{results}/{run}/{dorado}/{model}/demux",
                results=results,
                dorado=dorado,
                model=config["dorado_basecaller"][dorado]["model"],
                run=run,
            )
        )

        # file_list.append(
        #     expand("{results}/{run}/{dorado}/{model}/trim/{sample}.bam",
        #         results=results,
        #         run=run,
        #         dorado=dorado,
        #         model=config["dorado_basecaller"][dorado]["model"],
        #         sample=samples,
        #     )
        # )

        file_list.append(
            expand("{results}/{run}/{dorado}/{model}/fastq/{sample}.fastq.gz",
                results=results,
                run=run,
                dorado=dorado,
                model=config["dorado_basecaller"][dorado]["model"],
                sample=samples,
            )
        )

    return file_list




rule all:
    input:
        run_dorado(),

        # expand("{results}/{guppy}/guppy_basecaller.available_workflows.txt",
        #     results=results,
        #     guppy=guppy,
        # ), # guppy basecaller available workflows

        # expand("{results}/{guppy}/{run}/{cfg_type}/guppy_basecaller/sequencing{ext}",
        #     results=results,
        #     guppy=guppy,
        #     run=run,
        #     cfg_type=cfg_type,
        #     ext=["_summary.txt", "_telemetry.js"]
        # ), # guppy basecaller directory

        # expand("{results}/{guppy}/{run}/{cfg_type}/guppy_basecaller_fastq/{pass_or_fail}",
        #     results=results,
        #     guppy=guppy,
        #     run=run,
        #     cfg_type=cfg_type,
        #     pass_or_fail=["pass", "fail"],
        # ), # one fastq for each barcode or alias

        # expand("{results}/{guppy}/{run}/{cfg_type}/fastq/sequencing_{ext}",
        #     results=results,
        #     guppy=guppy,
        #     run=run,
        #     cfg_type=cfg_type,
        #     ext=["summary.txt.gz", "telemetry.js"]
        # ), # gzipped sequencing_summary in fastq dir

        # expand("{results}/{guppy}/{run}/{cfg_type}/fastq/{sample}.fastq.gz",
        #     results=results,
        #     guppy=guppy,
        #     run=run,
        #     cfg_type=cfg_type,
        #     sample=samples,
        # ), # pass fastq files

        # expand("{results}/{guppy}/{run}/{cfg_type}/fastq/fastq.md5",
        #     results=results,
        #     guppy=guppy,
        #     run=run,
        #     cfg_type=cfg_type,
        # ), # md5

        # expand("{results}/{guppy}/{run}/{cfg_type}/fastq/qc/fastq_overview/{run}.fastq_overview.{ext}",
        #     results=results,
        #     guppy=guppy,
        #     run=run,
        #     cfg_type=cfg_type,
        #     ext=["tsv",]
        # ), # flowcell stats on all fastq

        # expand("{results}/{guppy}/{run}/{cfg_type}/fastq/qc/fastq_overview/{run}.fastq_overview.{ext}",
        #     results=results,
        #     guppy=guppy,
        #     run=run,
        #     cfg_type=cfg_type,
        #     ext=["html",]
        # ), # flowcell stats on all fastq

        # expand("{results}/{guppy}/{run}/{cfg_type}/fastq/qc/fastqc/{sample}{ext}",
        #     results=results,
        #     guppy=guppy,
        #     run=run,
        #     cfg_type=cfg_type,
        #     sample=samples,
        #     ext=[".html", "_fastqc.zip"]
        # ), # fastqc

        # expand("{results}/{guppy}/{run}/{cfg_type}/fastq/qc/multiqc/{run}.multiqc.html",
        #     results=results,
        #     guppy=guppy,
        #     run=run,
        #     cfg_type=cfg_type,
        #     sample=samples,
        # ), # multiqc

        # ## pycoQC
        # expand("{results}/{guppy}/{run}/{cfg_type}/run_qc/pycoQC/{run}.{cfg_type}.pycoQC.{ext}",
        #     results=results,
        #     guppy=guppy,
        #     run=run,
        #     cfg_type=cfg_type,
        #     ext=["html", "json"]
        # ),

        # ## NanoPlot
        # expand("{results}/{guppy}/{run}/{cfg_type}/run_qc/NanoPlot/NanoPlot-report.html",
        #     results=results,
        #     guppy=guppy,
        #     run=run,
        #     cfg_type=cfg_type,
        # ),

        # ## MultiQC
        # expand("{results}/{guppy}/{run}/{cfg_type}/run_qc/{run}.{cfg_type}.MultiQC.html",
        #     results=results,
        #     guppy=guppy,
        #     run=run,
        #     cfg_type=cfg_type,
        # ),

        # ## dorado.smk
        # ## pod5
        # expand("{results}/{run}/pod5/{run}.{ext}",
        #     results=results,
        #     guppy=guppy,
        #     run=run,
        #     ext=["pod5", "summary.tsv.gz"]
        # ),




## rules ###############################################################################################################

# rule guppy_basecaller_available_workflows:
#     output:
#         "{results}/{guppy}/guppy_basecaller.available_workflows.txt"
#     params:
#         bin=lambda wildcards: config["guppy_basecaller"][wildcards.guppy]["bin"],
#     shell:
#         "{params.bin} "
#         "--print_workflows "
#         ">{output} "


# ## cfg
# checkpoint guppy_basecaller:
#     output:
#         summary_txt="{results}/{guppy}/{run}/{cfg_type}/guppy_basecaller/sequencing_summary.txt",
#         telemetry_js="{results}/{guppy}/{run}/{cfg_type}/guppy_basecaller/sequencing_telemetry.js"
#     params:
#         bin=lambda wildcards: config["guppy_basecaller"][wildcards.guppy]["bin"],
#         parameter=lambda wildcards: config["guppy_basecaller"][wildcards.guppy]["parameter"],
#         input_dir=config["run"]["input_dir"],
#         output_dir="{results}/{guppy}/{run}/{cfg_type}/guppy_basecaller",
#         barcode_kits=f"--barcode_kits {' '.join(config['run']['barcode_kits'])}" if config["run"]["barcode_kits"] else "",
#         sample_sheet=f"--sample_sheet {config['run']['sample_sheet']}" if config["run"]["sample_sheet"] else "",
#         n_gpu = 1,
#         wait_log=wait_log,
#     log:
#         "{results}/{guppy}/{run}/{cfg_type}/guppy_basecaller/guppy_basecaller.log"
#     benchmark:
#         "{results}/{guppy}/{run}/{cfg_type}/.benchmark/guppy_basecaller.{guppy}.{run}.{cfg_type}.benchmark.txt"
#     resources:
#         gpu_requests=1,
#     shell:
#         # "sleep $[ ( $RANDOM % 10 ) + 1 ]s; " # initial sleep
#         # "workflow/scripts/wait.sh -l {params.wait_log}; " # wait.sh
#         # "GPU=$(workflow/scripts/which_gpu ); "
#         # "echo GPU$GPU; "
#         "{params.bin} "
#         # "-x cuda:$GPU "
#         "-x cuda:0 "
#         "{params.parameter} "
#         "{params.sample_sheet} "
#         "{params.barcode_kits} "
#         "--config {wildcards.cfg_type}.cfg " # <--- use cfg file!!!
#         "--input_path {params.input_dir} "
#         "--save_path {params.output_dir} "
#         ">{log} 2>&1; "
#         "echo $?; "


# rule guppy_basecaller_fastq:
#     input:
#         "{results}/{guppy}/{run}/{cfg_type}/guppy_basecaller/sequencing_summary.txt"
#     output:
#         directory("{results}/{guppy}/{run}/{cfg_type}/guppy_basecaller_fastq/{pass_or_fail}")
#     params:
#         indir="{results}/{guppy}/{run}/{cfg_type}/guppy_basecaller/{pass_or_fail}"
#     benchmark:
#         "{results}/{guppy}/{run}/{cfg_type}/.benchmark/guppy_basecaller_fastq.{pass_or_fail}.benchmark.txt"
#     conda:
#         "envs/pigz.yaml"
#     threads:
#         4
#     shell:
#         "[ -d {output} ] || mkdir -p {output}; "
#         "( "
#         "samples=$(ls -1 {params.indir} | sort); "
#         "for sample in $samples; do "
#         "echo $sample; "
#         "fastqs=$(find {params.indir}/$sample -name '*.fastq.gz' | sort); "
#         """echo -e "$fastqs\n"; """
#         "zcat $fastqs "
#         "| pigz -p {threads} --best "
#         ">{output}/${{sample}}.fastq.gz; "
#         "done "
#         ") "
#         ">{output}/{wildcards.pass_or_fail}.txt "


# rule fastq_sequencing_summary:
#     input:
#         txt="{results}/{guppy}/{run}/{cfg_type}/guppy_basecaller/sequencing_summary.txt",
#         js="{results}/{guppy}/{run}/{cfg_type}/guppy_basecaller/sequencing_telemetry.js"
#     output:
#         txt="{results}/{guppy}/{run}/{cfg_type}/fastq/sequencing_summary.txt.gz",
#         js="{results}/{guppy}/{run}/{cfg_type}/fastq/sequencing_telemetry.js"
#     conda:
#         "envs/pigz.yaml"
#     threads:
#         4
#     shell:
#         "cat {input.txt} "
#         "| pigz -p {threads} --best "
#         ">{output.txt}; "
#         "cp {input.js} {output.js} "


# rule fastq:
#     input:
#         "{results}/{guppy}/{run}/{cfg_type}/guppy_basecaller_fastq/pass"
#     output:
#         "{results}/{guppy}/{run}/{cfg_type}/fastq/{sample}.fastq.gz"
#     params:
#         outdir="{results}/{guppy}/{run}/{cfg_type}/fastq"
#     shell:
#         "cp {input}/{wildcards.sample}.fastq.gz "
#         "{params.outdir} "


# rule fastq_md5:
#     input:
#         fastq=expand("{{results}}/{{guppy}}/{{run}}/{{cfg_type}}/fastq/{sample}.fastq.gz",
#             sample=samples,
#         ),
#         txt_gz="{results}/{guppy}/{run}/{cfg_type}/fastq/sequencing_summary.txt.gz",
#         js="{results}/{guppy}/{run}/{cfg_type}/fastq/sequencing_telemetry.js",
#     output:
#         "{results}/{guppy}/{run}/{cfg_type}/fastq/fastq.md5"
#     params:
#         indir="{results}/{guppy}/{run}/{cfg_type}/fastq"
#     shell:
#         ""
#         "bash workflow/scripts/md5_make "
#         "{params.indir} "


# ## breaks on ikim!!!
# rule fastq_overview:
#     input:
#         expand("{{results}}/{{guppy}}/{{run}}/{{cfg_type}}/guppy_basecaller_fastq/{pass_or_fail}",
#             pass_or_fail=["pass", "fail"]
#         )
#     output:
#         "{results}/{guppy}/{run}/{cfg_type}/fastq/qc/fastq_overview/{run}.fastq_overview.tsv"
#     params:
#         indir="{results}/{guppy}/{run}/{cfg_type}/guppy_basecaller_fastq"
#     shell:
#         "( "
#         """echo -e "sample\tqc\treads\tbases"; """
#         "fastqs=$(find {params.indir} -name '*.fastq.gz' | sort); "
#         "for f in $fastqs; do "
#         "qc=$(dirname $f | xargs basename); "
#         "sample=$(basename ${{f%.fastq.gz}}); "
#         "reads=$(zcat $f | sed -n '1~4p' | wc -l); "
#         """bases=$(zcat $f | sed -n '2~4p' | awk 'BEGIN{{FS=""}}{{for(i=1;i<=NF;i++)c++}}END{{print c}}'); """
#         """echo -e "$sample\t$qc\t$reads\t$bases"; """
#         "done; "
#         ") "
#         ">{output}; "


# rule fastq_flowcell_stats_figures:
#     input:
#         tsv="{results}/{guppy}/{run}/{cfg_type}/fastq/qc/fastq_overview/{run}.fastq_overview.tsv"
#     output:
#         "{results}/{guppy}/{run}/{cfg_type}/fastq/qc/fastq_overview/{run}.fastq_overview.html"
#     params:
#         run="{run} - {cfg_type}"
#     conda:
#         "envs/python.yaml"
#     ## log:
#     ##     notebook="{results}/{guppy}/{run}/{cfg_type}/fastq/qc/fastq_overview/{run}.fastq_stats.ipynb"
#     notebook:
#         "notebooks/minion_basecalling_stats.ipynb"


# rule fastq_fastqc:
#     input:
#         "{results}/{guppy}/{run}/{cfg_type}/fastq/{sample}.fastq.gz"
#     output:
#         html="{results}/{guppy}/{run}/{cfg_type}/fastq/qc/fastqc/{sample}.html",
#         zip="{results}/{guppy}/{run}/{cfg_type}/fastq/qc/fastqc/{sample}_fastqc.zip" # the suffix _fastqc.zip is necessary for multiqc to find the file. If not using multiqc, you are free to choose an arbitrary filename
#     params:
#         "--quiet"
#     threads:
#         2
#     wrapper:
#         "v3.1.0/bio/fastqc"


# rule multiqc:
#     input:
#         expand("{{results}}/{{guppy}}/{{run}}/{{cfg_type}}/fastq/qc/fastqc/{sample}{ext}",
#             sample=samples,
#             ext=[".html", "_fastqc.zip"]
#         )
#     output:
#         "{results}/{guppy}/{run}/{cfg_type}/fastq/qc/multiqc/{run}.multiqc.html"
#     params:
#         ""  # Optional: extra parameters for multiqc.
#     log:
#         "{results}/{guppy}/{run}/{cfg_type}/fastq/qc/multiqc/{run}.multiqc.log"
#     wrapper:
#         "v3.1.0/bio/multiqc"

