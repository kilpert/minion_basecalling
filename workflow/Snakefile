import glob
import os
import pandas as pd
import re


## resources ###########################################################################################################

try:
    workflow.global_resources["gpu_requests"]
except:
    workflow.global_resources["gpu_requests"] = 1


## 1st level of config variable definition: config.yaml ################################################################
try:
    configfile: "config/config.yaml"
except:
    pass


## 2nd level of config variable definition: snakemake command line args (overwrites previous definitions) ##############


## 3rd level of config variable definition: Snakefile (overwrites previous definitions) ################################

## outdir
try:
    results = config["output_dir"]
except:
    config["output_dir"] = "results"
    results = config["output_dir"]


try:
    config["guppy_basecaller"]
except:
    config["guppy_basecaller"] = "guppy_basecaller"


try:
    m = re.search("(.+).cfg", config["run"]["cfg"])
    config["guppy_basecaller"]["cfg_type"]  = m.group(1)
except:
    config["guppy_basecaller"]["cfg_type"] = f"{config['run']['flowcell']}_{config['run']['library_prep_kit']}"
    flowcell_and_kit = config["guppy_basecaller"]["cfg_type"]
cfg_type = config["guppy_basecaller"]["cfg_type"]


try:
    config["run"]["part"] = sorted(config["run"]["input_dir"].keys())
except:
    pass


try:
    config["run"]["barcode_kit"]
except:
    config["run"]["barcode_kit"] = None


try:
    config["demultiplexing"]
except:
    if not "barcode_kit" in config["run"]:
        config["demultiplexing"] = False
    else:
        config["demultiplexing"] = False


## config ##############################################################################################################

print("{:#^60}".format(" Config "))
print(json.dumps(config, sort_keys=True, indent=4))


## sample_sheet ########################################################################################################

print("{:#^60}".format(" sample_sheet (selected columns) "))

# df = pd.read_csv(config["run"]["sample_sheet"])
##print(df)

## dataframe for samples in samplesheet
# dfs = df[["barcode", "alias"]]
# print(dfs)


def get_dfl(df, barcodes):
    """extend df by barcodes"""
    dfb = pd.DataFrame({"barcode": barcodes, "alias": barcodes })
    return pd.concat([df, dfb.loc[~dfb["barcode"].isin(df["barcode"].values)]])


def get_alias(df, barcode):
    return df[df["barcode"]==barcode]["alias"].values[0]


def get_barcode(df, alias):
        return df[df["alias"]==alias]["barcode"].values[0]


## variables ###########################################################################################################

print("{:#^60}".format(" Variables "))


print("results:", results)


try:
    alias = config["run"]["alias"]
except:
    pass
print("alias:", alias)


part = config["run"]["part"]
print("part:", part)


print("cfg_type:", cfg_type)


## include #############################################################################################################

##include: "rules/qc.smk"


## snakemake: all ######################################################################################################

print("{:#^60}".format(" Workflow "))


# ## basecalling ##
# def guppy_basecaller_fastq_output(wildcards):
#     checkpoint_output = checkpoints.guppy_basecaller.get(results=results, run=run, cfg_type=cfg_type).output[0]
#     w = glob_wildcards(checkpoint_output+"/{pass_or_fail}/{barcode}/{bname}.fastq.gz")
#     return expand("{results}/{run}/{cfg_type}/guppy_basecaller_fastq/{pass_or_fail}/{barcode}.fastq.gz",
#         results=results,
#         run=run,
#         cfg_type=cfg_type,
#         pass_or_fail=sorted(list(set(w.pass_or_fail))),
#         barcode=sorted(list(set(w.barcode))),
#     )
#     return []


## alias

def guppy_basecaller_fastq_alias_output(wildcards):
    checkpoint_output = checkpoints.guppy_basecaller.get(results=results, run=run, cfg_type=cfg_type).output[0]
    w = glob_wildcards(checkpoint_output+"/{pass_or_fail}/{barcode}/{bname}.fastq.gz")
    barcodes = sorted(list(set(w.barcode)))
    dfl = get_dfl(dfs, barcodes)
    alias = [get_alias(dfl, b) for b in barcodes if b in dfl["barcode"].values]
    ## print("alias:", alias, len(alias))
    return expand("{results}/{run}/{cfg_type}/guppy_basecaller_fastq_alias/{pass_or_fail}/{alias}.fastq.gz",
        results=results,
        run=run,
        cfg_type=cfg_type,
        pass_or_fail=sorted(list(set(w.pass_or_fail))),
        alias=alias
    )


def fastq_alias_stats_output(wildcards):
    return expand("{results}/{run}/{cfg_type}/guppy_basecaller_fastq_alias/fastq_stats.tsv",
        results=results,
        run=run,
        cfg_type=cfg_type,
    )


def fastq_output(wildcards):
    checkpoint_output = checkpoints.guppy_basecaller.get(results=results, run=run, cfg_type=cfg_type).output[0]
    w = glob_wildcards(checkpoint_output+"/{pass_or_fail}/{barcode}/{bname}.fastq.gz")
    barcodes = sorted(list(set(w.barcode)))
    alias = [get_alias(dfs, b) for b in barcodes if b in dfs["barcode"].values]
    ## print("alias:", alias, len(alias))
    return expand("{results}/{run}/{cfg_type}/fastq/{pass_or_fail}/{alias}.fastq.gz",
        results=results,
        run=run,
        cfg_type=cfg_type,
        pass_or_fail=sorted(list(set(w.pass_or_fail))),
        alias=alias
    )

def fastq_fastqc_output(wildcards):
    checkpoint_output = checkpoints.guppy_basecaller.get(results=results, run=run, cfg_type=cfg_type).output[0]
    w = glob_wildcards(checkpoint_output+"/{pass_or_fail}/{barcode}/{bname}.fastq.gz")
    barcodes = sorted(list(set(w.barcode)))
    alias = [get_alias(dfs, b) for b in barcodes if b in dfs["barcode"].values]
    ## print("alias:", alias, len(alias))
    return expand("{results}/{run}/{cfg_type}/fastq/{pass_or_fail}/fastqc/{alias}{ext}",
        results=results,
        run=run,
        cfg_type=cfg_type,
        pass_or_fail=sorted(list(set(w.pass_or_fail))),
        alias=alias,
        ext=[".html", "_fastqc.zip"]
    )


def fastq_multiqc_output(wildcards):
    checkpoint_output = checkpoints.guppy_basecaller.get(results=results, run=run, cfg_type=cfg_type).output[0]
    w = glob_wildcards(checkpoint_output+"/{pass_or_fail}/{barcode}/{bname}.fastq.gz")
    barcodes = sorted(list(set(w.barcode)))
    alias = [get_alias(dfs, b) for b in barcodes if b in dfs["barcode"].values]
    ## print("alias:", alias, len(alias))
    return expand("{results}/{run}/{cfg_type}/fastq/{pass_or_fail}/multiqc/{run}.{pass_or_fail}.multiqc.html",
        results=results,
        run=run,
        cfg_type=cfg_type,
        pass_or_fail=sorted(list(set(w.pass_or_fail))),
    )


def read_lengths_output(wildcards):
    checkpoint_output = checkpoints.guppy_basecaller.get(results=results, run=run, cfg_type=cfg_type).output[0]
    w = glob_wildcards(checkpoint_output+"/{pass_or_fail}/{barcode}/{bname}.fastq.gz")
    barcodes = sorted(list(set(w.barcode)))
    alias = [get_alias(dfs, b) for b in barcodes if b in dfs["barcode"].values]
    ## print("alias:", alias, len(alias))
    return expand("{results}/{run}/{cfg_type}/fastq/{pass_or_fail}/read_lengths/tsv/{alias}.read_lengths.tsv",
        results=results,
        run=run,
        cfg_type=cfg_type,
        pass_or_fail=sorted(list(set(w.pass_or_fail))),
        alias=alias
    )


def read_length_plots_output(wildcards):
    checkpoint_output = checkpoints.guppy_basecaller.get(results=results, run=run, cfg_type=cfg_type).output[0]
    w = glob_wildcards(checkpoint_output+"/{pass_or_fail}/{barcode}/{bname}.fastq.gz")
    barcodes = sorted(list(set(w.barcode)))
    alias = [get_alias(dfs, b) for b in barcodes if b in dfs["barcode"].values]
    ## print("alias:", alias, len(alias))
    return expand("{results}/{run}/{cfg_type}/fastq/{pass_or_fail}/read_lengths/{run}.{cfg_type}.{pass_or_fail}.read_lengths.html",
        results=results,
        run=run,
        cfg_type=cfg_type,
        pass_or_fail=sorted(list(set(w.pass_or_fail))),
        alias=alias
    )


def demultiplexing():
    if config["demultiplexing"]:
        return [
            ## guppy_basecaller_fastq_alias_output, # temp
            ## fastqc_alias_output, # crashes at fail/unclassified by out of memory

            expand("{results}/{run}/{cfg_type}/guppy_basecaller_fastq_alias/{run}.flowcell.fastq_stats.tsv",
                results=results,
                run=run,
                cfg_type=cfg_type,
            ),

            expand("{results}/{run}/{cfg_type}/guppy_basecaller_fastq_alias/{run}.flowcell.fastq_stats.html",
                results=results,
                run=run,
                cfg_type=cfg_type,
            ),

            fastq_output,
            fastq_fastqc_output,
            fastq_multiqc_output,

            expand("{results}/{run}/{cfg_type}/fastq/{run}.fastq_stats.tsv",
                results=results,
                run=run,
                cfg_type=cfg_type,
            ),

            read_lengths_output,
            read_length_plots_output,

            ## PycoQC
            expand("{results}/{run}/{cfg_type}/run_qc/PycoQC/{run}.{cfg_type}.sequencing_summary.{ext}",
                results=results,
                run=run,
                cfg_type=cfg_type,
                ext=["html", "json"]
            ),

            expand("{results}/{run}/{cfg_type}/run_qc/{run}.{cfg_type}.multiqc.html",
                results=results,
                run=run,
                cfg_type=cfg_type,
            ),
        ]
    else:
        return []


## rule all ############################################################################################################

rule all:
    input:
        expand("{results}/{alias}/guppy_basecaller.available_workflows.txt",
            results=results,
            alias=alias,
        ), # optional

        expand("{results}/{alias}/{cfg_type}/part/{part}/guppy_basecaller/sequencing_summary.txt",
            results=results,
            alias=alias,
            cfg_type=cfg_type,
            part=part,
        ), # guppy basecalling

##         expand("{results}/{alias}/{cfg_type}/part/{part}/fastq/{pass_or_fail}/{part}.{pass_or_fail}.fastq.gz",
##             results=results,
##             alias=alias,
##             cfg_type=cfg_type,
##             part=part,
##             pass_or_fail=["pass", "fail"],
##         ), # concat basecalling fastqs

        expand("{results}/{alias}/{cfg_type}/part/{part}/fastq/{pass_or_fail}/fastqc/{part}.{pass_or_fail}_fastqc.html",
            results=results,
            alias=alias,
            cfg_type=cfg_type,
            part=part,
            pass_or_fail=["pass", "fail"],
        ), # part fastq fastqc

        expand("{results}/{alias}/{cfg_type}/part/multiqc/{alias}.part.multiqc.html",
            results=results,
            alias=alias,
            cfg_type=cfg_type,
        ), # part fastq multiqc

        expand("{results}/{alias}/{cfg_type}/fastq/{pass_or_fail}/{alias}.{pass_or_fail}.fastq.gz",
            results=results,
            alias=alias,
            cfg_type=cfg_type,
            part=part,
            pass_or_fail=["pass", "fail"],
        ), # concat fastq from parts

        expand("{results}/{alias}/{cfg_type}/fastq/{pass_or_fail}/fastqc/{alias}.{pass_or_fail}{ext}",
            results=results,
            alias=alias,
            cfg_type=cfg_type,
            pass_or_fail=["pass", "fail"],
            ext=["_fastqc.html", "_fastqc.zip"]
        ), # fastq fastqc

        expand("{results}/{alias}/{cfg_type}/fastq/multiqc/{alias}.multiqc.html",
            results=results,
            alias=alias,
            cfg_type=cfg_type,
        ), # fastq multiqc

##         expand("{results}/{alias}/{cfg_type}/fastq/sequencing_summary.txt",
##             results=results,
##             alias=alias,
##             cfg_type=cfg_type,
##         ), # fastq concat sequencing_summary

        expand("{results}/{alias}/{cfg_type}/fastq/pycoQC/{alias}.{cfg_type}.sequencing_summary.{ext}",
            results=results,
            alias=alias,
            cfg_type=cfg_type,
            pass_or_fail=["pass", "fail"],
            ext=["html", "json"]
        ), # pycoQC

        expand("{results}/{alias}/{cfg_type}/fastq/fastq.md5",
            results=results,
            alias=alias,
            cfg_type=cfg_type,
        ), # fastq md5


## rules ###############################################################################################################

rule guppy_basecaller_available_workflows:
    output:
        "{results}/{alias}/guppy_basecaller.available_workflows.txt"
    params:
        bin=config["guppy_basecaller"]["bin"],
    shell:
        "{params.bin} "
        "--print_workflows "
        ">{output} "


if config["guppy_basecaller"]["cfg_type"] == flowcell_and_kit:
    ## flowcell+kit
    rule guppy_basecaller:
        output:
            "{results}/{alias}/{cfg_type}/part/{part}/guppy_basecaller/sequencing_summary.txt"
        params:
            bin=config["guppy_basecaller"]["bin"],
            parameter=config["guppy_basecaller"]["parameter"],
            input_dir=lambda wildcards: config["run"]["input_dir"][wildcards.part],
            output_dir="{results}/{alias}/{cfg_type}/part/{part}/guppy_basecaller",
            flowcell=config["run"]["flowcell"],
            kit=config["run"]["library_prep_kit"],
            ## sample_sheet=config["run"]["sample_sheet"],
        log:
            "{results}/{alias}/{cfg_type}/log/{alias}.{part}.guppy_basecaller.log"
        benchmark:
            "{results}/{alias}/{cfg_type}/.benchmark/guppy_basecaller.{alias}.{cfg_type}.{part}.benchmark.txt"
        resources:
            gpu_requests=1
        shell:
            "{params.bin} "
            "{params.parameter} "
            "--flowcell {params.flowcell} "
            "--kit {params.kit} "
            ## "--sample_sheet {params.sample_sheet} "
            "--input_path {params.input_dir} "
            "--save_path {params.output_dir} "
            ">{log} 2>&1 "
else:
    ## cfg
    rule guppy_basecaller:
        output:
            "{results}/{alias}/{cfg_type}/part/{part}/guppy_basecaller/sequencing_summary.txt"
        params:
            bin=config["guppy_basecaller"]["bin"],
            parameter=config["guppy_basecaller"]["parameter"],
            input_dir=lambda wildcards: config["run"]["input_dir"][wildcards.part],
            output_dir="{results}/{alias}/{cfg_type}/part/{part}/guppy_basecaller",
            cfg=config["run"]["cfg"], # <--------------------------------------------------------------- use cfg file!!!
            barcode_kit=f"--barcode_kits {config['run']['barcode_kit']}" if config["run"]["barcode_kit"] else "",
            ## sample_sheet=config["run"]["sample_sheet"],
        log:
            "{results}/{alias}/{cfg_type}/log/{alias}.{part}.guppy_basecaller.log"
        benchmark:
            "{results}/{alias}/{cfg_type}/.benchmark/guppy_basecaller.{alias}.{cfg_type}.{part}.benchmark.txt"
        resources:
            gpu_requests=1
        shell:
            "{params.bin} "
            "{params.parameter} "
            "--config {params.cfg} " # <---------------------------------------------------------------- use cfg file!!!
            ## "--sample_sheet {params.sample_sheet} "
            "--input_path {params.input_dir} "
            "--save_path {params.output_dir} "
            "{params.barcode_kit} "
            ">{log} 2>&1 "


## concat all fastq files for each barcode
rule guppy_basecaller_concat_fastq:
    input:
        "{results}/{alias}/{cfg_type}/part/{part}/guppy_basecaller/sequencing_summary.txt"
    output:
        temp("{results}/{alias}/{cfg_type}/part/{part}/fastq/{pass_or_fail}/{part}.{pass_or_fail}.fastq.gz")
    params:
        indir="{results}/{alias}/{cfg_type}/part/{part}/guppy_basecaller/{pass_or_fail}"
    benchmark:
        "{results}/{alias}/{cfg_type}/.benchmark/guppy_basecaller_concat_fastq.{alias}.{cfg_type}.{part}.{pass_or_fail}.benchmark.txt"
    threads:
        4
    shell:
        "zcat $(ls {params.indir}/*.fastq.gz | sort) "
        "| pigz -p {threads} --best "
        ">{output} "
        "|| "
        "echo '' | gzip >{output} " # fix crash if there are no input files!!!


rule part_fastq_fastqc:
    input:
        "{results}/{alias}/{cfg_type}/part/{part}/fastq/{pass_or_fail}/{part}.{pass_or_fail}.fastq.gz"
    output:
        "{results}/{alias}/{cfg_type}/part/{part}/fastq/{pass_or_fail}/fastqc/{part}.{pass_or_fail}_fastqc.html"
    params:
        outdir="{results}/{alias}/{cfg_type}/part/{part}/fastq/{pass_or_fail}/fastqc/",
        temp="{results}/{alias}/{cfg_type}/part/{part}/fastq/{pass_or_fail}/fastqc/{part}.{pass_or_fail}_fastqc.html"
    log:
        "{results}/{alias}/{cfg_type}/log/{alias}.{part}.{pass_or_fail}.fastq_fastqc.log"
    conda:
        "envs/fastqc.yaml"
    threads:
        8 # need a lot of memory (250 MB per thread)
    shell:
        "fastqc "
        "--threads {threads} "
        "-o {params.outdir} "
        "{input} "
        ">{log} 2>&1 "
        ##"&& mv {params.temp} {output} " # rename output file


rule part_fastq_multiqc:
    input:
        expand("{{results}}/{{alias}}/{{cfg_type}}/part/{part}/fastq/{pass_or_fail}/fastqc/{part}.{pass_or_fail}_fastqc.html", part=part, pass_or_fail=["pass", "fail"])
    output:
        "{results}/{alias}/{cfg_type}/part/multiqc/{alias}.part.multiqc.html"
    params:
        extra=" --title '{alias} (Parts) - {cfg_type}' --fullnames",
    log:
        "{results}/{alias}/{cfg_type}/log/{alias}.fastq_part_multiqc.log"
    conda:
        "envs/multiqc.yaml"
    wrapper:
       "v1.3.2/bio/multiqc"


rule concat_part_fastq:
    input:
        expand("{{results}}/{{alias}}/{{cfg_type}}/part/{part}/fastq/{{pass_or_fail}}/{part}.{{pass_or_fail}}.fastq.gz", part=part)
    output:
        "{results}/{alias}/{cfg_type}/fastq/{pass_or_fail}/{alias}.{pass_or_fail}.fastq.gz"
    threads:
        4
    shell:
        "zcat {input} "
        "| pigz -p {threads} --best "
        ">{output} "
        "|| "
        "echo '' | gzip >{output} " # fix crash if there are no input files!!!


rule fastq_fastqc:
    input:
        "{results}/{alias}/{cfg_type}/fastq/{pass_or_fail}/{alias}.{pass_or_fail}.fastq.gz"
    output:
        html="{results}/{alias}/{cfg_type}/fastq/{pass_or_fail}/fastqc/{alias}.{pass_or_fail}_fastqc.html",
        zip="{results}/{alias}/{cfg_type}/fastq/{pass_or_fail}/fastqc/{alias}.{pass_or_fail}_fastqc.zip" # the suffix _fastqc.zip is necessary for multiqc to find the file. If not using multiqc, you are free to choose an arbitrary filename
    params:
        outdir="{results}/{alias}/{cfg_type}/fastq/{pass_or_fail}/fastqc/",
        extra=""
    log:
        "{results}/{alias}/{cfg_type}/log/{alias}.{pass_or_fail}.fastq_fastqc.log"
    conda:
        "envs/fastqc.yaml"
    threads:
        8 # need a lot of memory (250 MB per thread)
    shell:
        "fastqc "
        "--threads {threads} "
        "{params.extra} "
        "-o {params.outdir} "
        "{input} "
        ">{log} 2>&1 "


rule fastq_multiqc:
    input:
        expand("{{results}}/{{alias}}/{{cfg_type}}/fastq/{pass_or_fail}/fastqc/{{alias}}.{pass_or_fail}_fastqc.html", pass_or_fail=["pass", "fail"])
    output:
        "{results}/{alias}/{cfg_type}/fastq/multiqc/{alias}.multiqc.html"
    params:
        extra=" --title '{alias} - {cfg_type}' --fullnames",
    log:
        "{results}/{alias}/{cfg_type}/log/{alias}.fastq_multiqc.log"
    wrapper:
       "v1.7.1/bio/multiqc"


## Could be misleading header from only one file!!!
## rule fastq_sequencing_summary:
##     input:
##         expand("{{results}}/{{alias}}/{{cfg_type}}/part/{part}/guppy_basecaller/sequencing_summary.txt", part=part)
##     output:
##         "{results}/{alias}/{cfg_type}/fastq/sequencing_summary.txt"
##     shell:
##         "( "
##         "head -1 {input[0]}; "
##         "cat {input} "
##         "| grep -v '^filename' "
##         ") "
##         ">{output} "


rule fastq_pycoQC:
    input:
        expand("{{results}}/{{alias}}/{{cfg_type}}/part/{part}/guppy_basecaller/sequencing_summary.txt", part=part)
    output:
        html="{results}/{alias}/{cfg_type}/fastq/pycoQC/{alias}.{cfg_type}.sequencing_summary.html",
        json="{results}/{alias}/{cfg_type}/fastq/pycoQC/{alias}.{cfg_type}.sequencing_summary.json"
    log:
        "{results}/{alias}/{cfg_type}/log/{alias}.{cfg_type}.pycoQC.log"
    conda:
        "envs/pycoqc.yaml"
    shell:
        "pycoQC "
        "--report_title '{wildcards.alias} - {wildcards.cfg_type}' "
        "--summary_file {input} "
        "--html_outfile {output.html} "
        "--json_outfile {output.json} "
        ">{log} 2>&1 "


rule fastq_md5:
    input:
        "{results}/{alias}/{cfg_type}/fastq/pycoQC/{alias}.{cfg_type}.sequencing_summary.html",
        "{results}/{alias}/{cfg_type}/fastq/multiqc/{alias}.multiqc.html",
        "{results}/{alias}/{cfg_type}/fastq/pycoQC/{alias}.{cfg_type}.sequencing_summary.html"
    output:
        "{results}/{alias}/{cfg_type}/fastq/fastq.md5"
    params:
        outdir="{results}/{alias}/{cfg_type}/fastq"
    shell:
        "workflow/scripts/md5_make {params.outdir} "


# def guppy_basecaller_fastq_input(wildcards):
#     checkpoint_output = str(checkpoints.guppy_basecaller.get(**wildcards).output[0])
#     return sorted(glob.glob(f"{checkpoint_output}/{wildcards.pass_or_fail}/*.fastq.gz"))
#
#
# rule guppy_basecaller_fastq:
#     input:
#         guppy_basecaller_fastq_input
#     output:
#         "{results}/{run}/{cfg_type}/guppy_basecaller_fastq/{pass_or_fail}/{alias}.fastq.gz"
#     threads:
#         2
#     shell:
#         "zcat {input} "
#         "| pigz -p {threads} --best "
#         ">{output} "
#         "|| "
#         "echo '' | gzip >{output} " # fix crash if there are no input files!!!


# def guppy_basecaller_fastq_input(wildcards):
#     checkpoint_output = str(checkpoints.guppy_basecaller.get(**wildcards).output[0])
#     paths = []
#
#     for f in glob.glob(checkpoint_output+"/**/*.fastq.gz", recursive=True):
#
#         m = re.search("/(unclassified|barcode\d+)/", f)
#         if m:
#             barcode = m.group(1)
#         else:
#             barcode = None
#
#         m = re.search("/(pass|fail)/", f)
#         if m:
#             pass_or_fail = m.group(1)
#         else:
#             pass_or_fail = None
#
#         if barcode==wildcards.barcode and pass_or_fail==wildcards.pass_or_fail:
#             paths.append(f)
#
#     paths = sorted(paths)
#
#     if not paths:
#         print(wildcards.barcode)
#
#     return paths
#
#
# ## concat all fastq files for each barcode
# rule guppy_basecaller_fastq:
#     input:
#         guppy_basecaller_fastq_input
#     output:
#         temp("{results}/{run}/{cfg_type}/guppy_basecaller_fastq/{pass_or_fail}/{barcode}.fastq.gz")
#     threads:
#         2
#     shell:
#         "zcat {input} "
#         "| pigz -p {threads} --best "
#         ">{output} "
#         "|| "
#         "echo '' | gzip >{output} " # fix crash if there are no input files!!!
#
#
# ## alias ###############################################################################################################
#
# def guppy_basecaller_fastq_alias_input(wildcards):
#     ##print( [wildcards.items] )
#     checkpoint_output = checkpoints.guppy_basecaller.get(results=results, run=run, cfg_type=cfg_type).output[0]
#     w = glob_wildcards(checkpoint_output+"/{pass_or_fail}/{barcode}/{bname}.fastq.gz")
#     barcodes = sorted(list(set(w.barcode)))
#     dfl = get_dfl(dfs, barcodes)
#     return expand("{results}/{run}/{cfg_type}/guppy_basecaller_fastq/{pass_or_fail}/{barcode}.fastq.gz",
#         results=results,
#         run=run,
#         cfg_type=cfg_type,
#         pass_or_fail=wildcards.pass_or_fail,
#         barcode=get_barcode(dfl, wildcards.alias)
#     )
#
#
# rule guppy_basecaller_fastq_alias:
#     input:
#         guppy_basecaller_fastq_alias_input
#     output:
#         temp("{results}/{run}/{cfg_type}/guppy_basecaller_fastq_alias/{pass_or_fail}/{alias}.fastq.gz")
#     shell:
#         "cp {input} {output} "


# def fastq_flowcell_stats_input(wildcards):
#     checkpoint_output = checkpoints.guppy_basecaller.get(results=results, run=run, cfg_type=cfg_type).output[0]
#     w = glob_wildcards(checkpoint_output+"/{pass_or_fail}/{barcode}/{bname}.fastq.gz")
#     barcodes = sorted(list(set(w.barcode)))
#     dfl = get_dfl(dfs, barcodes)
#     alias = [get_alias(dfl, b) for b in barcodes if b in dfl["barcode"].values]
#     ## print("alias:", alias, len(alias))
#     return expand("{results}/{run}/{cfg_type}/guppy_basecaller_fastq_alias/{pass_or_fail}/{alias}.fastq.gz",
#         results=results,
#         run=run,
#         cfg_type=cfg_type,
#         pass_or_fail=sorted(list(set(w.pass_or_fail))),
#         alias=alias
#     )
#
#
# rule fastq_flowcell_stats:
#     input:
#         fastq_flowcell_stats_input
#     output:
#         "{results}/{run}/{cfg_type}/guppy_basecaller_fastq_alias/{run}.flowcell.fastq_stats.tsv"
#     shell:
#         "( "
#         """echo -e "sample\tqc\treads\tbases"; """
#         "for f in {input}; do "
#         "sample=$(basename ${{f%.fastq.gz}}); "
#         "qc=$(basename $(dirname ${{f%.fastq.gz}})); "
#         "reads=$(zcat $f | sed -n '1~4p' | wc -l); "
#         """bases=$(zcat $f | sed -n '2~4p' | awk 'BEGIN{{FS=""}}{{for(i=1;i<=NF;i++)c++}}END{{print c}}'); """
#         """echo -e "$sample\t$qc\t$reads\t$bases"; """
#         "done"
#         ") "
#         ">{output}; "


# rule fastq_flowcell_stats_figures:
#     input:
#         tsv="{results}/{run}/{cfg_type}/guppy_basecaller_fastq_alias/{run}.flowcell.fastq_stats.tsv"
#     output:
#         "{results}/{run}/{cfg_type}/guppy_basecaller_fastq_alias/{run}.flowcell.fastq_stats.html"
#     params:
#         run="{run} - {cfg_type}"
#     conda:
#         "envs/python.yaml"
#     ##log:
#     ##    notebook="{results}/{run}/{cfg_type}/guppy_basecaller_fastq_alias/{run}.fastq_stats.ipynb"
#     notebook:
#         "notebooks/minion_basecalling_stats.ipynb"
#
#
# rule fastq:
#     input:
#         "{results}/{run}/{cfg_type}/guppy_basecaller_fastq_alias/{pass_or_fail}/{alias}.fastq.gz"
#     output:
#         "{results}/{run}/{cfg_type}/fastq/{pass_or_fail}/{alias}.fastq.gz"
#     params:
#         in_path="../../guppy_basecaller_fastq_alias/{pass_or_fail}/{alias}.fastq.gz"
#     shell:
#         "cp {input} {output} "
#         ##"ln -s {params.in_path} {output} "
#
#
# rule fastq_fastqc:
#     input:
#         "{results}/{run}/{cfg_type}/fastq/{pass_or_fail}/{alias}.fastq.gz"
#     output:
#         html="{results}/{run}/{cfg_type}/fastq/{pass_or_fail}/fastqc/{alias}.html",
#         zip="{results}/{run}/{cfg_type}/fastq/{pass_or_fail}/fastqc/{alias}_fastqc.zip" # the suffix _fastqc.zip is necessary for multiqc to find the file. If not using multiqc, you are free to choose an arbitrary filename
#     params:
#         "--quiet"
#     threads:
#         2
#     wrapper:
#         "v1.3.2/bio/fastqc"
#
#
# def multiqc_input(wildcards):
#     checkpoint_output = checkpoints.guppy_basecaller.get(results=results, run=run, cfg_type=cfg_type).output[0]
#     w = glob_wildcards(checkpoint_output+"/{pass_or_fail}/{barcode}/{bname}.fastq.gz")
#     barcodes = sorted(list(set(w.barcode)))
#     alias = [get_alias(dfs, b) for b in barcodes if b in dfs["barcode"].values]
#     ## print("alias:", alias, len(alias))
#     return expand("{{results}}/{{run}}/{{cfg_type}}/fastq/{pass_or_fail}/fastqc/{alias}_fastqc.zip",
#         pass_or_fail=wildcards.pass_or_fail,
#         alias=alias,
#     )
#
#
# rule multiqc:
#     input:
#         multiqc_input
#     output:
#         "{results}/{run}/{cfg_type}/fastq/{pass_or_fail}/multiqc/{run}.{pass_or_fail}.multiqc.html"
#     params:
#         ""  # Optional: extra parameters for multiqc.
#     log:
#         "{results}/{run}/{cfg_type}/fastq/{pass_or_fail}/multiqc/{run}.{pass_or_fail}.multiqc.log"
#     wrapper:
#         "v1.3.2/bio/multiqc"
#
#
# def fastq_stats_input(wildcards):
#     checkpoint_output = checkpoints.guppy_basecaller.get(results=results, run=run, cfg_type=cfg_type).output[0]
#     w = glob_wildcards(checkpoint_output+"/{pass_or_fail}/{barcode}/{bname}.fastq.gz")
#     barcodes = sorted(list(set(w.barcode)))
#     alias = [get_alias(dfs, b) for b in barcodes if b in dfs["barcode"].values]
#     return expand("{{results}}/{{run}}/{{cfg_type}}/fastq/{pass_or_fail}/{alias}.fastq.gz",
#         pass_or_fail=sorted(list(set(w.pass_or_fail))),
#         alias=alias,
#     )
#
#
# rule fastq_stats:
#     input:
#         fastq_stats_input
#     output:
#         "{results}/{run}/{cfg_type}/fastq/{run}.fastq_stats.tsv"
#     shell:
#         "( "
#         """echo -e "sample\tqc\treads\tbases"; """
#         "for f in {input}; do "
#         "sample=$(basename ${{f%.fastq.gz}}); "
#         "qc=$(basename $(dirname ${{f%.fastq.gz}})); "
#         "reads=$(zcat $f | sed -n '1~4p' | wc -l); "
#         """bases=$(zcat $f | sed -n '2~4p' | awk 'BEGIN{{FS=""}}{{for(i=1;i<=NF;i++)c++}}END{{print c}}'); """
#         """echo -e "$sample\t$qc\t$reads\t$bases"; """
#         "done"
#         ") "
#         ">{output}; "
#
#
# rule read_lengths:
#     input:
#         "{results}/{run}/{cfg_type}/fastq/{pass_or_fail}/{alias}.fastq.gz"
#     output:
#         "{results}/{run}/{cfg_type}/fastq/{pass_or_fail}/read_lengths/tsv/{alias}.read_lengths.tsv"
#     shell:
#         "( "
#         "echo -e 'n\tbp'; "
#         "zcat {input} "
#         "| sed -n '2~4p' "
#         "| awk '{{print length}}' "
#         "| sort -n "
#         "| uniq -c"
#         "| sed 's/^ *//g' "
#         "| sed 's/ /\t/' "
#         ") "
#         ">{output} "
#
#
# def read_length_plots_input(wildcards):
#     checkpoint_output = checkpoints.guppy_basecaller.get(results=results, run=run, cfg_type=cfg_type).output[0]
#     w = glob_wildcards(checkpoint_output+"/{pass_or_fail}/{barcode}/{bname}.fastq.gz")
#     barcodes = sorted(list(set(w.barcode)))
#     alias = [get_alias(dfs, b) for b in barcodes if b in dfs["barcode"].values]
#     return expand("{{results}}/{{run}}/{{cfg_type}}/fastq/{{pass_or_fail}}/read_lengths/tsv/{alias}.read_lengths.tsv",
#         ##pass_or_fail=sorted(list(set(w.pass_or_fail))),
#         alias=alias,
#     )
#
#
# rule read_length_plots:
#     input:
#         tsv=read_length_plots_input
#     output:
#         "{results}/{run}/{cfg_type}/fastq/{pass_or_fail}/read_lengths/{run}.{cfg_type}.{pass_or_fail}.read_lengths.html"
#     params:
#         run="{run} - {cfg_type} ({pass_or_fail})"
#     conda:
#         "envs/python.yaml"
#     ##log:
#     ##    notebook="{results}/{run}/{cfg_type}/guppy_basecaller_fastq_alias/{run}.fastq_stats.ipynb"
#     notebook:
#         "notebooks/read_length_plots.ipynb"
#
#
